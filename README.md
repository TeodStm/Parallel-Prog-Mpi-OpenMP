Για την αρχιτεκτονική MPI η κάθε διεργασία γνωρίζοντας τις διαστάσεις του αρχικού πίνακα, υπολογίζει τις διαστάσεις των συμμετρικών υποπινάκων που θα διασπαστεί ο αρχικός. Έχοντας στην κατοχή της ένα συμμετρικό υποπίνακα του αρχικού, τον αρχικοποιεί με τυχαίες τιμές. Στη συνέχεια η κάθε διεργασία, μέσω καρτεσιανής τοπολογίας, βρίσκει τους γείτονές της που θα επικοινωνήσει έπειτα για τον διαμοιρασμό δεδομένων. Στο κεντρικό for το οποίο εκτελεί 500 επαναλήψεις εξυπηρετεί τον υπολογισμό του τελικού τοπικού πίνακα.
Στην υλοποίηση του MPI με σύγκλιση η συνάρτηση MPI_AllReduce καλείται ανά 50 επαναλήψεις , όπου κάθε διεργασία εξετάζει αν υπάρχει διαφορά μεταξύ του προηγούμενου και του τρέχοντος τοπικού πίνακα και μέσω αυτής της συνάρτησης εντοπίζουμε αν υπάρχει συνολική σύγκλιση.
Στην υβριδική υλοποίηση MPI με OpenMP ακολουθείται η ίδια λογική με πριν με τη διαφορά να εντοπίζεται στο κεντρικό for όπου κάνουμε επιπλέον παραλληλοποιήσεις μέσω νημάτων (#pragma). Τα σημεία αυτά είναι το for όπου υπολογίζουμε τα κεντρικά στοιχεία του νέου τοπικού πίνακα, για τα στοιχεία της πρώτης και της τελευταίας σειράς και της πρώτης και τελευταίας στήλης.
